%from chapin2013:  An individual bolometer acts as a thermal absorber which are linked directly to transition edge sensors.  When the sensors detect detect thermal variations they will produce changing currents which result in changing magnetic fields.  The magnetic fields are detected by super conduction quantum interference devices (SQUIDs) prior to the output currents being digitized.  Between the initial SQUID amplification and digitization of the current, the data is resampled from 12KHz to 200Hz.  A chain of ``dark SQUIDs'' is used to detect any non-thermal noise that can arise from the amplification of the signal.  //all unnecessary....


\chapter{Observations and Data Preparation}\label{observations}

\section{SCUBA-2} \\
The Submillimetre Common-User Bolometer Array 2 (SCUBA-2) was designed to decrease the observing time compared its predecessor SCUBA to allow for rapid data acquisition in the submillimetre regime of the electromagnetic spectrum, at the 450$\mu$m and 850$\mu$m bands.  Prior to SCUBA-2, other bolometer camera's such as LABOCA, BOLOCAM and SHARC-II were limited to less than 100 pixels, while the new SCUBA-2 has been able to incorporate over 10,000 pixels in its design and effectively reduce observing time.  Increasing the amount of pixels by a factor of 100 was possible by the advent of new technology such as high precision micromachining, superconducting transition edge sensors, and superconducting quantum interference device amplifiers \citet{holland2013}.

The observations of NGC3627 were taken from the Nearby Galaxies Legacy Survey's (NGLS) initial science images using SCUBA-2 from December 29, 2011  to January 21, 2012, and consist of 24 18`x18` scans taken in grade 3 weather or better $(0.08 < \tau <0.12)$.  Out of the 24 scans, 16 were deemed useable.  Whether or not an observation was deemed worthwhile was determined by factors such as the behavior of the image background and whether the image was flagged in observing to be unusable.  An example of a good image background vs a poor image background can be seen in figure \ref{fig_bg}.  The observations of NGC3627 were taken using a daisy scanning pattern at 600``/second in order to reduce the white noise of the final data product.

\section{Image Creation and Properties}

For any imaging process to have been successful, the image needed to have limited white noise.  White noise in the sense of our bolometer observations arose from thermal variations in the instrument and atmosphere during data acquisition. The random noise can be minimized through scanning methods and during image processing \citet{chapin2013}.  To create the final SCUBA-2 data products we used the Submillimetre User Reduction Facility (SMURF) procedure MAKEMAP.  This procedure reduced the noise of the observations while maintaining the source's emission by incorporating a combination of principal component analysis and a maximum likelihood analysis \citet{chapin2013}.  Both of these methods have proven useful in reducing bolometer data on their own, but due to the size of raw SCUBA-2 data, specific aspects of each method would result in extreme run times or the process becoming resource intensive.

MAKEMAP broke down the image creation into several steps performed in iteration in order to successfully reduce any background noise \citet{chapin2013}.  The steps used in MAKEMAP were:  COM and GAI which remove any common noise features detected by the superconducting quantum interface devices (SQUIDs), EXT to apply extinction corrections, FLT applied  a high- and low-pass filters to remove any noise features not removed in the COM and GAI filtering, AST which regrids the data and detects sources to be removed from reduction, the final step is NOI which determines the noise in the gridded map after each step has been performed.  A convergence check is then issued and if the check failed the COM, GAI, EXT, and FLT values are inverted and the process is repeated.

%might be a good idea to reference the dimmconfig file we used as well as provide a copy of the final dimmconfig
In our production of maps, we altered the AST and FLT sections of the image creation by introducing a mask made from Herschel's 250$\mu$m map shown if figure \ref{ngc3627_mask}.  The purpose of the map was to exclude the target from interfering with the noise minimization as well as prohibit any emission from the galaxy to be significantly altered during image production.  The filter size of the high-pass filter was also modified and an appropriate value was determined to be 175Hz.  The maps were returned from MAKEMAP in units of pW with a pixel size of 2 square arc seconds for both the 450$\mu$m and 850$\mu$m.

The finalized 450$\mu$m image was then re-gridded down to a 4`` by 4`` pixel grid, and a flux calibration value of 491000 and 4710 were applied to convert from pW to mJy/beam and mJy/sq arc second respectively.  The 850$\mu$m maps were re-gridded to an 8`` by 8`` pixel size and used flux calibration values of 537000 and 2340 for mJy/beam and mJy/sq. arc second.   For ease of analysis the images were also converted to Jy/pixel by multiplying the mJy/sq arc seond by 0.001/pixel area.  The calibration values were determined from observations of Uranus.   The overall noise in the finalized image scan be seen in table \ref{obs_tab}.

\subsection{Beam Shape of the 450$\mu$m and 850$\mu$m} \\
The Uranus calibration images were also used in determining the shape of the beam for the 450$\mu$m and 850$\mu$m observations.  The beam shape of both the 450$\mu$ and 850$\mu$m deviate from a single gaussian due to the second maximum of the airy diffraction pattern in the response function of the telescope.  This abnormality was best represented by a sum of two gaussians whose amplitude totals to unity \citet{dempsey2013}.  The average beam resolution for the 450$\mu$m and 850$\mu$m are reported in table \ref{obs_tab} and match the values within error found in \citet{dempsey2013}.  The contribution of the error beam in the 850$\mu$m emission was negligible and allowed for the beam to be approximated by a single gaussian however the contribution of the error beam in the 450$\mu$m images was large enough to require special treatment.

In order to accommodate the 450$\mu$m's error component, we used a method employed by another SCUBA-2 survey team, the Gould-Belt Survey team.  This method utilized the distributive nature of the Fourier transform to create similar error components in the beam resolutions we were convolving to and from.  This relationship is shown in equation \ref{eq:GBSmethod} where $X_{desire}$ is the beam width of the resolution we are convolving to, $\alpha$ is the amplitude of the main beam of the 450$\mu$m emission, $\beta$ is the amplitude of the 450$\mu$m error beam, $X_{\alpha}$ and $X_{\beta}$ are the main and error beam of the 450$\mu$m observations, and $X_{450\mu m}$ is the composition of $X_{\alpha}$ and $X_{\beta}$ beams.

\begin{equation} \label{eq:GBSmethod}
  \left(X_{desire} \ast X_{\alpha}\right)*\alpha + \left(X_{desire} \ast X_{\beta}\right)*\beta = X_{450\mu m} \ast X_{desire}
\end{equation}

\section{Ancillary Data}

The science goals of this thesis required data outside the capabilities of SCUBA-2.  Determining the dust mass needed the spectral energy distribution (SED) for NGC3627 to be accurately fit.  To successfully fit an SED, we needed shorter wavelength data to fully probe the cold component of this galaxy. We used data ranging from 100$\mu$m to 500$\mu$ from the KINGFISH survey \citet{kennicutt2011} to fulfill this need.  Secondly, the bandpass of the 850$\mu$m emisison contains the $CO_{j=3-2}$ transmission line.  In order to get a valid approximation on the dust mass, this contribution had to be removed.  We used emmisison data from the NGLS using HARP instrumentation on the JCMT \citet{wilson2012}.  When a dust mass was obtained, we used $CO_{j=1-0}$ from the Nobeyama 45-m telescope (\citet{kuno2007}), $CO_{j=2-1}$ from HERACLES (\citet{leroy2009}), and $HI$ observations from THINGS (\citet{walter2008}).

Due to the combination of methods used in MAKEMAP, small scale/extended structure is removed from the final SCUBA-2 images.  However, in all of our ancillary data the small scale emission was present in the initial maps.  The removal of the extended features from our support data was carried out by converting the images from their native units into pW using the 850$\mu$m flux calibration factor.  The images were overlaid on the original scans as a fakesource and passed through the reduction process.  The original scan was then subtracted from the scan with the fakesource present and the residual of the process was the ancillary data with its extended structure removed.%  The amount of emission lost can be seen in figure \ref{fig_fs_lost}.

\subsection{Key Insights on Nearby Galaxies: a Far-Infrared Survey with Herschel (KINGFISH)}

%include an extended removed map for each data set
The Key Insights on Nearby Galaxies: a Far-Infrared Survey with Herschel (KINGSFISH) was designed to be a follow up to the Spitzer Infrared Nearby Galaxies Survey (SINGS) with observations of the warm and cold component of dust emission using the increased resolution from Herschel \citet{kennicutt2011}.  The main science goals of the KINGFISH survey were to better understand the processes of star formation that were shielded by dust, resolved studies of heating and cooling of the interstellar medium (ISM), and to build an inventory of how cold dust emission relates to other dust components in the ISM \citet{kennicutt2011}.  The survey consisted of studying 61 nearby galaxies (d$<$30Mpc) that cover a range of environments each observed at 70$\mu$m, 100$\mu$, 160$\mu$m, 250$\mu$m, 350$\mu$m, and 500$\mu$m.  

We were interested in fitting the cold component of NGC3627's SED, hence we omitted the 70$\mu$m emission, and used the 100$\mu$m, 160$\mu$m, 250$\mu$m, 350$\mu$m and 500$\mu$m.  Since the Kingfish data was acquired by a space-based telescope, a significant amount of small scale emission was recovered due to the lack of interference from the atmosphere.  The small scale emission was removed by treating the KINGFISH data as a fakesource in the image reduction process.  The first step to successfully incorporating the data as a fakesource was to convert the 250$\mu$m, 350$\mu$m, and 500$\mu$m from MJy/sr to mJy/sq. arc second, and similarly the 100$\mu$m and 160$\mu$m from Jy/pixel to mJy/sq. arc second.   After the unit conversion, the 850$\mu$m flux calibration factor was applied in reverse, and the new image was then scaled down to better mimic the 850$\mu$m emission.  After these steps the image was passed into MAKEMAP and treated as an 850$\mu$m image.  The final data output were gridded to 8'' x 8'' pixels and can be seen in figures \ref{100_fs} to \ref{500_fs}.  The beam size and rms for each image after it has been passed through make map can be seen in table \ref{obs_tab}.

\subsection{Nearby Galaxy Legacy Survey (NGLS)}

The Nearby Galaxy Legacy Survey is an HI-selected set of 155 galaxies contained in the annulus of $2Mpc\leq r \leq25Mpc$ using the instrumentation aboard the JCMT \citet{wilson2012}.  The NGLS contains data observed in several wavelengths that include the 450$\mu$m and 850$\mu$m data used for this thesis.  As mentioned previously, the bandpass for SCUBA-2's 850$\mu$m emission contains the $CO_{j=3-2}$ line which is contained in the NGLS data set.  We used the zeroth moment $CO_{j=3-2}$ maps from the NGLS to determine the percentage of $CO_{j=3-2}$ emission present in the 850$\mu$ band as well as removing it for an accurate SED analysis.  

Removing the molecular gas contamination from the 850$\mu$m images required passing the data through MAKEMAP in a similar manner as the KINGFISH data.  The only significant difference was converting the $CO_{j=3-2}$ data from $K*km/s$ to pW.  The change of units was done using conversion factor of 0.70 $[K*km/s][mJy/beam]^{-1}$ found by \citet{drabek2012}.  The final image product can be seen in figure \ref{fig_co32}.  We found the average ratio of $CO_{j=3-2}$ to be around 25\% in most of the galaxy while rising as high as 50\% in the nucleus indicative of AGN activity.

\subsection{Nobeyama 45-m $CO_{j=1-0}$}

Determining a dust-to-gas ratio required the need for a molecular tracer.  The most frequently used molecular tracer is $CO_{j=1-0}$ due to it's abundance in the ISM.  The $CO_{j=1-0}$ we used was taken from the Nobeyama 45-m CO Atlas of Nearby Spiral Galaxies and observed to better understand the roll of bars relating to molecular gas \citet{kuno2007}.  Preparation for the $CO_{j=1-0}$ was performed in a similar matter to the previous ancillary data sets, however instead of determining a direct conversion factor the data was scaled down by a factor 0.001.  The scaling factor used was selected so that the input image for the fakesoure would be on the same scale as the 850$\mu$m image it was overwriting, and then re-applied as the flux calibration factor to return the original map into its native unit of $K * (km/s)$.  The beam sizes and rms of the filterd $CO_{j=1-0}$ map are displayed in table \ref{obs_tab}.

\subsection{HERA CO-Line Extragalactic Survey (HERACLES) $CO_{j=2-1}$}
test
\subsection{The HI Nearby Galaxy Survey (THINGS)}

%this information would be useful to include into maybe subsection for the 450 and 850 that would include things like calibration to uranus, beam sizes, and then pixel information

%location of fig_bg is: /1/home/newtonjh/scuba2_test/ngc3627/previous/work_dir/scans/thesis_fig

%need to check the scan speed of SCUBA-2

%I should have some filter plot lying around somewhere.  Get it.

%build obs_tab to have the beamsizes and rms values for each of the observations post makemap and then used for SED processing along with the corresponding convolving beams(?).
%  info for the table:

%maybe include some beam shapes with the calibration data?

%include bandwidth for 450um and 850um!!

%look for plots showing the amount of emission lost due to fakesourcing

%make a table that shows how much emission was removed through processing.

%need full images of all the fs data.
%------


%\section{SCUBA-2}
%\begin{itemize}
%   \item What is SCUBA-2 and what does it look at and why is it an important/how is it relevant among today's instrumentation
%   \item Discuss the nature of the observations and their reduction, things like weather grade, number of images used.  Technical details.
%   \item maybe include figure of emission window for scuba-2
%\end{itemize}

%\subsection{Image Creation}
%\begin{itemize}
%   \item Use SMURF MAKEMAP command and give brief description of overall process.  Include $img_gen.sh$ in an appendix?
%   \item Implement maps in the ast and flt portion of makemap.  Explain what these do for the image overall (should reduce noise and help to flatten background)
%   \item use flt.filtering to remove any large scale features.  Helped with smoothing background noises.
%   \item apply FCF values that are determined from calibrations from Uranus
%   \item 850 gridded to 8sq'' and 450 gridded to 4sq'' pixels.
%   \end{itemize}

%\subsection{Image Properties of 450$\mu$m and 850$\mu$m}
%\begin{itemize}
%   \item for 850$\mu$m needed to remove $CO_{j=3-2}$ emission from continuum band.  Reference the drabek paper and a brief outline of what she did.  QUOTE THE NUMBER USED TO CONVERT UNITS. <-- where to include this?
%   \item show calibration data?
%   \item beam shape of 450 and 850.  Discuss fitting methods for both single and double gaussian shapes also give rms values of noise before any convolution.
%   \item show beams in color image w/contour and plot across the middle
%\end{itemize}

%\section{Supporting Images / ancillary data}

%\begin{itemize}
%  \item Discuss what you need other images for.  Herschel for SED fits.  THINGS, KUNO, and Heracles for dust-to-gas ratio.
%  \item Images needed to be run through makemap as a fake source in order to remove any small scale structure from original images.  I should have several figures showing the amount of flux removed from each of the images.
%  \item Reference the Kingfish Survey, Kuno et al., Heracles survey and THINGS survey for their sources.  <--Leave this as a paragraph on it's own or introduce smaller subsections?
  
%\end{itemize}

